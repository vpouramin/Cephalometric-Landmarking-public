{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXNH6V2Orl2x"
      },
      "source": [
        "Creating standard folders for dataset :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crEwBN2Qti46"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/dataset\n",
        "!mkdir /content/dataset\n",
        "\n",
        "!mkdir /content/dataset/test\n",
        "!mkdir /content/dataset/train\n",
        "!mkdir /content/dataset/valid\n",
        "\n",
        "!mkdir /content/dataset/test/images\n",
        "!mkdir /content/dataset/test/labels\n",
        "\n",
        "!mkdir /content/dataset/train/images\n",
        "!mkdir /content/dataset/train/labels\n",
        "\n",
        "!mkdir /content/dataset/valid/images\n",
        "!mkdir /content/dataset/valid/labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVtJJjxPyQGF"
      },
      "source": [
        "Reducing image size on memory :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi6cfZ-G6hQO"
      },
      "outputs": [],
      "source": [
        "image_format = '.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXC0is5bycGk"
      },
      "source": [
        "Copying training images in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxzVRNNCyxd9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "train_img_path = '/content/data/RawImage/TrainingData/'\n",
        "destination_path = '/content/dataset/train/images/'\n",
        "# Iterate directory\n",
        "for filename in os.listdir(train_img_path):\n",
        "  image = cv2.imread(train_img_path + filename)\n",
        "  cv2.imwrite('/content/dataset/train/images/'+filename.replace('.bmp', image_format), image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da8QKq-iygml"
      },
      "source": [
        "Copying testing images in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PXWvnDavhPk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "test_img_path = '/content/data/RawImage/Test1Data/'\n",
        "destination_path = '/content/dataset/test/images/'\n",
        "# Iterate directory\n",
        "for filename in os.listdir(test_img_path):\n",
        "  image = cv2.imread(test_img_path + filename)\n",
        "  cv2.imwrite('/content/dataset/test/images/'+filename.replace('.bmp', image_format), image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PShdz7uhygOk"
      },
      "source": [
        "Copying validation images in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K44CTN0iyylG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "valid_img_path = '/content/data/RawImage/Test2Data/'\n",
        "destination_path = '/content/dataset/valid/images/'\n",
        "# Iterate directory\n",
        "for filename in os.listdir(valid_img_path):\n",
        "  image = cv2.imread(valid_img_path + filename)\n",
        "  cv2.imwrite('/content/dataset/valid/images/'+filename.replace('.bmp', image_format), image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xRtzoCruhHE"
      },
      "source": [
        "Checking images size in train folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycscR9Sduktp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for i in range(1,151,1):\n",
        "  sourceimage = '/content/dataset/train/images/' + '{0:03}'.format(i)+image_format\n",
        "  image = Image.open(sourceimage)\n",
        "  print(image.size)\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGQ37LfDv7L"
      },
      "source": [
        "Defining some variables :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUfBtwlUur2S"
      },
      "outputs": [],
      "source": [
        "img_width = 1935\n",
        "img_height = 2400\n",
        "bb_margin = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBG1fwbwEEit"
      },
      "source": [
        "Converting point to bounding box :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffkTAQE6l6wt"
      },
      "outputs": [],
      "source": [
        "def xy_to_bbox(xy, margin = 10, width = img_width, height = img_height):\n",
        "  x = int(xy[0])\n",
        "  y = int(xy[1])\n",
        "  return [str(x/width), str(y/height), str((2*margin)/width), str((2*margin)/height)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g1sJxXaJEju"
      },
      "source": [
        "Copying training annotation in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4PAsJQ35eBR"
      },
      "outputs": [],
      "source": [
        "for i in range(1,151,1):\n",
        "  sourcefile = '/content/data/annotations/400_senior/' + '{0:03}'.format(i)+'.txt'\n",
        "  destinationfile = '/content/dataset/train/labels/' + '{0:03}'.format(i)+'.txt'\n",
        "\n",
        "  fp = open(destinationfile, 'w')\n",
        "  with open(sourcefile) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox(line, margin = bb_margin, width = img_width, height = img_height)\n",
        "      content = str(x)\n",
        "      for item in line:\n",
        "        content = content + ' ' + item\n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXf-A-gPJHv0"
      },
      "source": [
        "Copying testing annotation in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPZ0nwUxIJar"
      },
      "outputs": [],
      "source": [
        "for i in range(151,301,1):\n",
        "  sourcefile = '/content/data/annotations/400_senior/' + '{0:03}'.format(i)+'.txt'\n",
        "  destinationfile = '/content/dataset/test/labels/' + '{0:03}'.format(i)+'.txt'\n",
        "\n",
        "  fp = open(destinationfile, 'w')\n",
        "  with open(sourcefile) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox(line, margin = bb_margin, width = img_width, height = img_height)\n",
        "      content = str(x)\n",
        "      for item in line:\n",
        "        content = content + ' ' + item\n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N67oJ11IJWnt"
      },
      "source": [
        "Copying validation annotation in dataset folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIx_k1oJITRo"
      },
      "outputs": [],
      "source": [
        "for i in range(301,401,1):\n",
        "  sourcefile = '/content/data/annotations/400_senior/' + '{0:03}'.format(i)+'.txt'\n",
        "  destinationfile = '/content/dataset/valid/labels/' + '{0:03}'.format(i)+'.txt'\n",
        "\n",
        "  fp = open(destinationfile, 'w')\n",
        "  with open(sourcefile) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox(line, margin = bb_margin, width = img_width, height = img_height)\n",
        "      content = str(x)\n",
        "      for item in line:\n",
        "        content = content + ' ' + item\n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eERgYnQfFIrA"
      },
      "source": [
        "----------------------------------------\n",
        "Defining some variables :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U29mN0wTzb4R"
      },
      "outputs": [],
      "source": [
        "img_width = 1935\n",
        "img_height = 2400\n",
        "augmentation_margin = 1\n",
        "bb_margin = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CayOP1RGFKzn"
      },
      "source": [
        "Installing image augmentation package :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onMP3e4foV44"
      },
      "outputs": [],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6QInkkjFRWO"
      },
      "source": [
        "Writing bounding box detailes for augmented images in annotation file in dataset folder :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmOy51meo9yX"
      },
      "outputs": [],
      "source": [
        "def write_annotation_to_file_augmentation(ih, iw, bbs, file_name):\n",
        "  fp = open(file_name, 'w')\n",
        "  for x in range(19):\n",
        "      content = ''\n",
        "      content = str(x)\n",
        "      content = content + ' ' + str(bbs[x][0]/iw) + ' ' + str(bbs[x][1]/ih) \\\n",
        "                        + ' ' + str(bbs[x][2]/iw) + ' ' + str(bbs[x][3]/ih)\n",
        "      \n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6UsmomTGGX5"
      },
      "source": [
        "Converting point to bounding box :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r60Hf7NYzG7i"
      },
      "outputs": [],
      "source": [
        "def xy_to_bbox_augmentation(xy, margin = 5, width = img_width, height = img_height):\n",
        "  x = int(xy[0])\n",
        "  y = int(xy[1])\n",
        "  return [(x - margin), (y - margin), (x + margin), (y + margin)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7jl9A_lGJhF"
      },
      "source": [
        "Converting augmented bbs to yolo specified format :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNuEVIj05Lbz"
      },
      "outputs": [],
      "source": [
        "def convert_bbox_to_yolo_format(bbs, margin = 10, width = img_width, height = img_height):\n",
        "  bb = []\n",
        "  for i in range(len(bbs)):\n",
        "    x = ((bbs[i][0][0] + bbs[i][1][0])/2)\n",
        "    y = ((bbs[i][0][1] + bbs[i][1][1])/2)\n",
        "    bb.append([x, y, (2*margin), (2*margin)])\n",
        "  return bb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_35LOmG4Yh"
      },
      "source": [
        "Function for applying 11 deferent augmentation method on each image :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjpnseqcANzf"
      },
      "outputs": [],
      "source": [
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug.parameters as iap\n",
        "import cv2\n",
        "\n",
        "aug1 = iaa.AdditiveLaplaceNoise(scale=0.1*255)\n",
        "aug2 = iaa.MultiplyElementwise((0.5, 1.5))\n",
        "aug3 = iaa.CoarseDropout((0.0, 0.05), size_percent=(0.02, 0.25))\n",
        "aug4 = iaa.CoarseSaltAndPepper(0.05, size_percent=(0.01, 0.1))\n",
        "aug5 = iaa.BlendAlphaSimplexNoise(iaa.EdgeDetect(1.0), sigmoid_thresh=iap.Normal(10.0, 5.0))\n",
        "aug6 = iaa.SigmoidContrast(gain=(3, 10), cutoff=(0.4, 0.6))\n",
        "aug7 = iaa.AllChannelsCLAHE()\n",
        "aug8 = iaa.Flipud(1.0)\n",
        "aug9 = iaa.Affine(rotate=(-45, 45))\n",
        "aug10 = iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
        "aug11 = iaa.Rot90([1, 3])\n",
        "\n",
        "def aug(image2, bbs):\n",
        "  images_aug, bbs_aug = aug1(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '1_' + image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '1_'+ image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print(i, ': 1', end = ' ')\n",
        "  \n",
        "  images_aug, bbs_aug = aug2(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '2_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '2_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('2', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug3(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '3_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '3_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('3', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug4(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '4_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '4_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('4', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug5(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '5_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '5_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('5', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug6(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '6_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '6_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('6', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug7(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '7_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '7_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('7', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug8(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '8_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '8_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('8', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug9(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '9_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '9_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('9', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug10(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '10_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '10_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('10', end = ' ')\n",
        "\n",
        "  images_aug, bbs_aug = aug11(images=image2, bounding_boxes=bbs)\n",
        "  bbs_aug = convert_bbox_to_yolo_format(bbs_aug, margin = bb_margin, width = img_width, height = img_height)\n",
        "  res = cv2.cvtColor(images_aug[0], cv2.COLOR_RGB2BGR)\n",
        "  img_file_name = destinationimagePath + '11_'+image_name\n",
        "  cv2.imwrite(img_file_name, res)\n",
        "  ann_file_name = destinationannotationPath + '11_'+image_name.replace(image_format, '.txt')\n",
        "  write_annotation_to_file_augmentation(ih, iw, bbs_aug, ann_file_name)\n",
        "  print('11')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrwv4IP1TNXB"
      },
      "source": [
        "Running augmentation on Trainning images folder on dataset :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQDznAjmo9uP"
      },
      "outputs": [],
      "source": [
        "destinationimagePath = '/content/dataset/train/images/'\n",
        "destinationannotationPath = '/content/dataset/train/labels/'\n",
        "\n",
        "for i in range(1,151,1):\n",
        "  image_name = '{0:03}'.format(i) + image_format\n",
        "  sourceimage = destinationimagePath + image_name\n",
        "  sourceannotation = '/content/data/annotations/400_senior/' + '{0:03}'.format(i) + '.txt'\n",
        "  bbs = []\n",
        "  \n",
        "  with open(sourceannotation) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox_augmentation(line, margin = augmentation_margin, width = img_width, height = img_height)\n",
        "      bbs.append(ia.BoundingBox(x1=line[0], y1=line[1], x2=line[2], y2=line[3],label = x))\n",
        "  \n",
        "  image = cv2.imread(sourceimage)\n",
        "  image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  ih = image.shape[0]\n",
        "  iw = image.shape[1]\n",
        "  image2 = image2.reshape(1, ih, iw, 3)\n",
        "\n",
        "  aug(image2, bbs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51sJz4MyTSCp"
      },
      "source": [
        "Running augmentation on Testing images folder on dataset :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_mK99nio9qP"
      },
      "outputs": [],
      "source": [
        "destinationimagePath = '/content/dataset/test/images/'\n",
        "destinationannotationPath = '/content/dataset/test/labels/'\n",
        "\n",
        "for i in range(151,301,1):\n",
        "  image_name = '{0:03}'.format(i) + image_format\n",
        "  sourceimage = destinationimagePath + image_name\n",
        "  sourceannotation = '/content/data/annotations/400_senior/' + '{0:03}'.format(i) + '.txt'\n",
        "  bbs = []\n",
        "  \n",
        "  with open(sourceannotation) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox_augmentation(line, margin = bb_margin, width = img_width, height = img_height)\n",
        "      bbs.append(ia.BoundingBox(x1=line[0], y1=line[1], x2=line[2], y2=line[3],label = x))\n",
        "  \n",
        "  image = cv2.imread(sourceimage)\n",
        "  image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  ih = image.shape[0]\n",
        "  iw = image.shape[1]\n",
        "  image2 = image2.reshape(1, ih, iw, 3)\n",
        "\n",
        "  aug(image2, bbs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr4u9eQUTXaH"
      },
      "source": [
        "Running augmentation on Validation images folder on dataset :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOAMWRzro9ex"
      },
      "outputs": [],
      "source": [
        "destinationimagePath = '/content/dataset/valid/images/'\n",
        "destinationannotationPath = '/content/dataset/valid/labels/'\n",
        "\n",
        "for i in range(301,401,1):\n",
        "  image_name = '{0:03}'.format(i) + image_format\n",
        "  sourceimage = destinationimagePath + image_name\n",
        "  sourceannotation = '/content/data/annotations/400_senior/' + '{0:03}'.format(i)+'.txt'\n",
        "  bbs = []\n",
        "  \n",
        "  with open(sourceannotation) as myfile:\n",
        "    for x in range(19):\n",
        "      content = ''\n",
        "      line = (next(myfile).strip().split(','))\n",
        "      line = xy_to_bbox_augmentation(line, margin = bb_margin, width = img_width, height = img_height)\n",
        "      bbs.append(ia.BoundingBox(x1=line[0], y1=line[1], x2=line[2], y2=line[3],label = x))\n",
        "  \n",
        "  image = cv2.imread(sourceimage)\n",
        "  image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  ih = image.shape[0]\n",
        "  iw = image.shape[1]\n",
        "  image2 = image2.reshape(1, ih, iw, 3)\n",
        "\n",
        "  aug(image2, bbs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaI-TuIOhWk7"
      },
      "source": [
        "----------------------------------------\n",
        "**Preparing hamedan_university database for yolov5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwCfziZe98wF"
      },
      "source": [
        "Creating standard split folder for train, test and validation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OggEjyd4gQkL"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/hamedan_university_dataset\n",
        "!mkdir /content/hamedan_university_dataset\n",
        "\n",
        "!mkdir /content/hamedan_university_dataset/test\n",
        "!mkdir /content/hamedan_university_dataset/train\n",
        "!mkdir /content/hamedan_university_dataset/valid\n",
        "\n",
        "!mkdir /content/hamedan_university_dataset/test/images\n",
        "!mkdir /content/hamedan_university_dataset/test/labels\n",
        "\n",
        "!mkdir /content/hamedan_university_dataset/train/images\n",
        "!mkdir /content/hamedan_university_dataset/train/labels\n",
        "\n",
        "!mkdir /content/hamedan_university_dataset/valid/images\n",
        "!mkdir /content/hamedan_university_dataset/valid/labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cM_c3d8gQdk"
      },
      "outputs": [],
      "source": [
        "training_ratio = 0.8\n",
        "bb_margin = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PFGDkJ0gQWM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "images_list = os.listdir('/content/hamedan_university/hamedan_university_dataset/pictures')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21uCxz3WgQIa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(images_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTzYpii6hjVi"
      },
      "outputs": [],
      "source": [
        "print(images_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjZCmR3MiOYm"
      },
      "outputs": [],
      "source": [
        "training_image_idx = round(training_ratio * len(images_list))\n",
        "testing_image_idx = training_image_idx + round(((1 - training_ratio)/2) * len(images_list))\n",
        "validation_image_idx = len(images_list)\n",
        "print (training_image_idx, testing_image_idx, validation_image_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtxqQBWYkXia"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def justify_annotation(file_name, bb_margin = 25):\n",
        "  with open(file_name, 'r') as f:\n",
        "    data = json.load(f)\n",
        "  \n",
        "  ih = data['imageHeight']\n",
        "  iw = data['imageWidth']\n",
        "  annotation = []\n",
        "  for i in data['shapes']:\n",
        "    label = i['label'][1::]\n",
        "    px = i['points'][0][0]\n",
        "    py = i['points'][0][1]\n",
        "    annotation.append([int(label)-1, (px/iw), (py/ih), (bb_margin/iw), (bb_margin/ih)])\n",
        "  return annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cczWPDKZiOLh"
      },
      "outputs": [],
      "source": [
        "def write_annotation_to_file(annotationf, annotationm, file_name):\n",
        "  fp = open(file_name, 'w')\n",
        "  for x in range(len(annotationf)):\n",
        "      #content = ''\n",
        "      line = annotationf[x]\n",
        "      content = str(line[0])\n",
        "      for item in line[1::]:\n",
        "        content = content + ' ' + str(item)\n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)\n",
        "  \n",
        "  for x in range(len(annotationm)):\n",
        "      #content = ''\n",
        "      line = annotationm[x]\n",
        "      content = str(line[0])\n",
        "      for item in line[1::]:\n",
        "        content = content + ' ' + str(item)\n",
        "      # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9_jQUm1iuCz"
      },
      "outputs": [],
      "source": [
        "dataset_image_path = \"/content/hamedan_university/hamedan_university_dataset/pictures/\"\n",
        "dataset_annotation_f = \"/content/hamedan_university/hamedan_university_dataset/annotated by Dr.farhadifar/\"\n",
        "dataset_annotation_m = \"/content/hamedan_university/hamedan_university_dataset/annotated by  Dr.mollabashi/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd8oEj6YiOAO"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import cv2\n",
        "for i in range(0, training_image_idx):\n",
        "  sourcefile = os.path.join(dataset_image_path, images_list[i])\n",
        "  destinationfile = '/content/hamedan_university_dataset/train/images/' + images_list[i].replace('.tif', '.jpg')\n",
        "  annotation_farhadifar = dataset_annotation_f + images_list[i].replace('.tif', '.json')\n",
        "  annotation_mollabashi = dataset_annotation_m + images_list[i].replace('.tif', '.json')\n",
        "  img = cv2.imread(sourcefile)\n",
        "  cv2.imwrite(destinationfile, img)\n",
        "  file_name = '/content/hamedan_university_dataset/train/labels/' + images_list[i].replace('.tif', '.txt')\n",
        "  if (Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_m, file_name)\n",
        "  elif (Path(annotation_farhadifar).is_file() and not Path(annotation_mollabashi).is_file()):\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_f, file_name)\n",
        "  elif (not Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_m, annotation_m, file_name)\n",
        "\n",
        "for i in range(training_image_idx, testing_image_idx):\n",
        "  sourcefile = os.path.join(dataset_image_path, images_list[i])\n",
        "  destinationfile = '/content/hamedan_university_dataset/test/images/' + images_list[i].replace('.tif', '.jpg')\n",
        "  annotation_farhadifar = dataset_annotation_f + images_list[i].replace('.tif', '.json')\n",
        "  annotation_mollabashi = dataset_annotation_m + images_list[i].replace('.tif', '.json')\n",
        "  img = cv2.imread(sourcefile)\n",
        "  cv2.imwrite(destinationfile, img)\n",
        "  file_name = '/content/hamedan_university_dataset/test/labels/' + images_list[i].replace('.tif', '.txt')\n",
        "  if (Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_m, file_name)\n",
        "  elif (Path(annotation_farhadifar).is_file() and not Path(annotation_mollabashi).is_file()):\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_f, file_name)\n",
        "  elif (not Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_m, annotation_m, file_name)\n",
        "\n",
        "for i in range(testing_image_idx, len(images_list)):\n",
        "  sourcefile = os.path.join(dataset_image_path, images_list[i])\n",
        "  destinationfile = '/content/hamedan_university_dataset/valid/images/' + images_list[i].replace('.tif', '.jpg')\n",
        "  annotation_farhadifar = dataset_annotation_f + images_list[i].replace('.tif', '.json')\n",
        "  annotation_mollabashi = dataset_annotation_m + images_list[i].replace('.tif', '.json')\n",
        "  img = cv2.imread(sourcefile)\n",
        "  cv2.imwrite(destinationfile, img)\n",
        "  file_name = '/content/hamedan_university_dataset/valid/labels/' + images_list[i].replace('.tif', '.txt')\n",
        "  if (Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_m, file_name)\n",
        "  elif (Path(annotation_farhadifar).is_file() and not Path(annotation_mollabashi).is_file()):\n",
        "    annotation_f = justify_annotation(annotation_farhadifar);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_f, annotation_f, file_name)\n",
        "  elif (not Path(annotation_farhadifar).is_file() and Path(annotation_mollabashi).is_file()):\n",
        "    annotation_m = justify_annotation(annotation_mollabashi);\n",
        "    img = cv2.imread(sourcefile)\n",
        "    cv2.imwrite(destinationfile, img)\n",
        "    write_annotation_to_file(annotation_m, annotation_m, file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guL8LDSGj2D1"
      },
      "source": [
        "--------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg10xGXY5bku"
      },
      "source": [
        "# **Yolo5 :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMWx1CJxSqDy"
      },
      "source": [
        "cloning yolo repository :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp0ht1d_xXnT"
      },
      "outputs": [],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAbt5Y6YleDD"
      },
      "source": [
        "**On yolov5 filder:**\n",
        "\n",
        "*   yolov5s_result  : before augmentation, train on ISBI\n",
        "*   yolov5s_result2 : after augmentation, train on ISBI\n",
        "*   yolov5s_result3 : fine tune on hamedan_university_dataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sc5xFjS0K6L"
      },
      "outputs": [],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOxrOoNs2jNs"
      },
      "outputs": [],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat ../dataset/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLhszPc212hL"
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(\"../dataset/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKRNSYp__Iu0"
      },
      "outputs": [],
      "source": [
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGmCT0Ky3sqa"
      },
      "outputs": [],
      "source": [
        "#this is the model configuration we will use for our tutorial \n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIe5yi5p3xkr"
      },
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh4u-zCh163u"
      },
      "source": [
        "**yolo5s :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tld7X5Tj31lf"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3SzQLzD2Atb"
      },
      "source": [
        "**yolo5x :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHEN8Ehe1PMy"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5x.yaml\n",
        "\n",
        "# Parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 1.33  # model depth multiple\n",
        "width_multiple: 1.25  # layer channel multiple\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 v6.0 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 v6.0 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpIXHnay5wbl"
      },
      "source": [
        "**Train :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqKMlaxz39HD"
      },
      "outputs": [],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "\n",
        "# YoloV5s\n",
        "!python train.py --img 416 --batch 16 --epochs 500 --data /content/dataset/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache\n",
        "\n",
        "# YoloV5x\n",
        "#!python train.py --img 416 --batch 16 --epochs 500 --data /content/dataset/data.yaml --cfg ./models/custom_yolov5x.yaml --weights '' --name yolov5x_results  --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIU8ovekNnB"
      },
      "source": [
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEt5DTUt6-Ue"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzoCYU7V7Brn"
      },
      "outputs": [],
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKLmwHij7HqE"
      },
      "outputs": [],
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnBDscC37LUb"
      },
      "outputs": [],
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEyCtME-5qFj"
      },
      "source": [
        "**Evaluation (ISBI) :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLwo8Wo-7Nwj"
      },
      "outputs": [],
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "\n",
        "# before augmentation\n",
        "#!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.3 --source ../dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19\n",
        "\n",
        "# after augmentation\n",
        "#!python detect.py --weights runs/train/yolov5s_results2/weights/best.pt --img 416 --conf 0.3 --source ../dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19\n",
        "\n",
        "# after fine tune\n",
        "!python detect.py --weights runs/train/yolov5s_results3/weights/best.pt --img 416 --conf 0.3 --source ../dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK7SdgTlxXwS"
      },
      "source": [
        "------------------------------------------\n",
        "**show grand truth on test images (ISBI):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ftOPuRGrgae"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/result\n",
        "!mkdir /content/result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2K9wERfUiGE"
      },
      "outputs": [],
      "source": [
        "# ISBI\n",
        "img_width = 1935\n",
        "img_height = 2400\n",
        "\n",
        "image_format = '.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iTWr1cJ6qMs"
      },
      "outputs": [],
      "source": [
        "test_images_path = '/content/yolov5/runs/detect/exp'\n",
        "test_labels_path = '/content/dataset/test/labels'\n",
        "result_path = '/content/result/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-aehihFjmb-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "images_list = os.listdir(test_images_path)\n",
        "for idx in range(len(images_list)):\n",
        "  image_name = test_images_path + '/' + images_list[idx]\n",
        "  label_name = test_labels_path + '/' + images_list[idx].replace(image_format,'.txt')\n",
        "  result_name =  result_path + images_list[idx].replace(image_format,'.jpg')\n",
        "  print(f'{images_list[idx]:<15}', end = '-')\n",
        "  print(\"%4d of %4d - %6.2f%%\" %((idx+1), len(images_list), ((idx + 1)/len(images_list) * 100)))\n",
        "  image = cv2.imread(image_name)\n",
        "  with open(label_name) as labelfile:\n",
        "    for x in range(19):\n",
        "      line = (next(labelfile).strip().split(' '))\n",
        "      x_value = int(float(line[1]) * img_width)\n",
        "      y_value = int(float(line[2]) * img_height)\n",
        "      cv2.circle(image, (x_value, y_value), 5, (0, 0, 0), 10)\n",
        "      cv2.putText(image, str(x+1), (x_value-15, y_value-15), cv2.FONT_HERSHEY_SIMPLEX , 1,(255, 0, 0), 2, cv2.LINE_AA)\n",
        "      cv2.imwrite(result_name, image)\n",
        "print('done')\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRKZyVkPXUXV"
      },
      "source": [
        "**Evaluation (hamedan_university):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NubI8RL4W53u"
      },
      "outputs": [],
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "\n",
        "# before augmentation\n",
        "#!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.3 --source ../hamedan_university_dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19\n",
        "\n",
        "# after augmentation\n",
        "#!python detect.py --weights runs/train/yolov5s_results2/weights/best.pt --img 416 --conf 0.3 --source ../hamedan_university_dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19\n",
        "\n",
        "# after fine tune\n",
        "!python detect.py --weights runs/train/yolov5s_results3/weights/best.pt --img 416 --conf 0.3 --source ../hamedan_university_dataset/test/images --iou-thres 0.0 --save-txt --hide-conf #--max-det 19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U33gEgYpiYOW"
      },
      "source": [
        "------------------------------------------\n",
        "**show grand truth on test images (hamedan_university):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wpUKRrLiYOW"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/result\n",
        "!mkdir /content/result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMvxSVnYiYOl"
      },
      "outputs": [],
      "source": [
        "# hamedan_university\n",
        "img_width = 1340\n",
        "img_height = 1671\n",
        "\n",
        "image_format = '.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9JzBJESiYOl"
      },
      "outputs": [],
      "source": [
        "test_images_path = '/content/yolov5/runs/detect/exp'\n",
        "test_labels_path = '/content/hamedan_university_dataset/test/labels'\n",
        "result_path = '/content/result/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrqOk5KgiYOl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "images_list = os.listdir(test_images_path)\n",
        "for idx in range(len(images_list)):\n",
        "  image_name = test_images_path + '/' + images_list[idx]\n",
        "  label_name = test_labels_path + '/' + images_list[idx].replace(image_format,'.txt')\n",
        "  result_name =  result_path + images_list[idx].replace(image_format,'.jpg')\n",
        "  print(f'{images_list[idx]:<15}', end = '-')\n",
        "  print(\"%4d of %4d - %6.2f%%\" %((idx+1), len(images_list), ((idx + 1)/len(images_list) * 100)))\n",
        "  image = cv2.imread(image_name)\n",
        "  cv2.putText(image, 'farhadifar', (50, 50), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
        "  cv2.putText(image, 'molabashi', (50, 100), cv2.FONT_HERSHEY_SIMPLEX , 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "  with open(label_name) as labelfile:\n",
        "    for x in range(19):\n",
        "      line = (next(labelfile).strip().split(' '))\n",
        "      x_value = int(float(line[1]) * img_width)\n",
        "      y_value = int(float(line[2]) * img_height)\n",
        "      cv2.circle(image, (x_value, y_value), 3, (255, 0, 0), 3)\n",
        "      cv2.putText(image, str((x%19)+1), (x_value-15, y_value-15), cv2.FONT_HERSHEY_SIMPLEX , 1,(255, 0, 0), 1, cv2.LINE_AA)\n",
        "      cv2.imwrite(result_name, image)\n",
        "    for x in range(19, 38):\n",
        "      line = (next(labelfile).strip().split(' '))\n",
        "      x_value = int(float(line[1]) * img_width)\n",
        "      y_value = int(float(line[2]) * img_height)\n",
        "      cv2.circle(image, (x_value, y_value), 3, (0, 255, 0), 3)\n",
        "      cv2.putText(image, str((x%19)+1), (x_value-15, y_value-15), cv2.FONT_HERSHEY_SIMPLEX , 1,(0, 255, 0), 1, cv2.LINE_AA)\n",
        "      cv2.imwrite(result_name, image)\n",
        "print('done')\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2R41iSNO8N6"
      },
      "source": [
        "**Calculating Overlap area (hamedan_university):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT-P70n3iCua"
      },
      "outputs": [],
      "source": [
        "detection_path = '/content/yolov5/runs/detect/exp/labels'\n",
        "label_path = '/content/hamedan_university_dataset/test/labels'\n",
        "img_width = 1340\n",
        "img_height = 1671\n",
        "margin = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZevkrOLHLMC2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def distance(a, b):  # returns 0 if rectangles don't intersect\n",
        "    return (math.dist([a.x, a.y], [b.x, b.y]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGLV5CEo3cOJ"
      },
      "source": [
        "**Farhadifar:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itmhF4qN3bwC",
        "outputId": "01b6eb0e-1ecc-49ca-829e-13d5aa415559"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from collections import namedtuple\n",
        "Point = namedtuple('Point', 'x y')\n",
        "\n",
        "csvfile = open('/content/detection_farhadifar.csv', 'w')\n",
        "headeres = ['image_name', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', \\\n",
        "              'L10', 'L11', 'L12', 'L13', 'L14', 'L15', 'L16', 'L17', 'L18', 'L19']\n",
        "writer = csv.writer(csvfile)\n",
        "writer.writerow(headeres)\n",
        "\n",
        "detection_list = os.listdir(detection_path)\n",
        "for idx in range(len(detection_list)):\n",
        "  cls_overlap_area = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
        "  file_name = detection_list[idx]\n",
        "  detection_name = detection_path + '/' + file_name\n",
        "  label_name = label_path + '/' + file_name\n",
        "\n",
        "  label_file = open(label_name, 'r')\n",
        "  label_Lines = label_file.readlines()\n",
        "\n",
        "  with open(detection_name) as detection_file:\n",
        "    detection_Lines = detection_file.readlines()\n",
        "    for detection_line in detection_Lines:\n",
        "      detection_line = detection_line.split(' ')\n",
        "      detection_cls = int(detection_line[0])\n",
        "      detection_x = int(float(detection_line[1]) * img_width)\n",
        "      detection_y = int(float(detection_line[2]) * img_height)\n",
        "\n",
        "      label_line = label_Lines[detection_cls].split(' ')\n",
        "      label_x = int(float(label_line[1]) * img_width)\n",
        "      label_y = int(float(label_line[2]) * img_height)\n",
        "\n",
        "      cls_overlap_area[0] = int(file_name.split('.')[0])\n",
        "\n",
        "      pa = Point(detection_x, detection_y)\n",
        "      pb = Point(label_x, label_y)\n",
        "      cls_overlap_area[detection_cls + 1] = distance(pa, pb)\n",
        "\n",
        "  writer.writerow(cls_overlap_area)\n",
        "csvfile.close()\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bB7_cDd3dVa"
      },
      "source": [
        "**Molabashi:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6WA1Ez_oe21",
        "outputId": "c6b07c29-05fc-4aa6-f700-380ccda317a5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from collections import namedtuple\n",
        "Point = namedtuple('Point', 'x y')\n",
        "\n",
        "csvfile = open('/content/detection_molabashi.csv', 'w')\n",
        "headeres = ['image_name', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', \\\n",
        "              'L10', 'L11', 'L12', 'L13', 'L14', 'L15', 'L16', 'L17', 'L18', 'L19']\n",
        "writer = csv.writer(csvfile)\n",
        "writer.writerow(headeres)\n",
        "\n",
        "detection_list = os.listdir(detection_path)\n",
        "for idx in range(len(detection_list)):\n",
        "  cls_overlap_area = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
        "  file_name = detection_list[idx]\n",
        "  detection_name = detection_path + '/' + file_name\n",
        "  label_name = label_path + '/' + file_name\n",
        "\n",
        "  label_file = open(label_name, 'r')\n",
        "  label_Lines = label_file.readlines()\n",
        "\n",
        "  with open(detection_name) as detection_file:\n",
        "    detection_Lines = detection_file.readlines()\n",
        "    for detection_line in detection_Lines:\n",
        "      detection_line = detection_line.split(' ')\n",
        "      detection_cls = int(detection_line[0])\n",
        "      detection_x = int(float(detection_line[1]) * img_width)\n",
        "      detection_y = int(float(detection_line[2]) * img_height)\n",
        "\n",
        "      label_line = label_Lines[detection_cls+19].split(' ')\n",
        "      # label_cls = int(label_line[0])\n",
        "      label_x = int(float(label_line[1]) * img_width)\n",
        "      label_y = int(float(label_line[2]) * img_height)\n",
        "\n",
        "      cls_overlap_area[0] = int(file_name.split('.')[0])\n",
        "\n",
        "      pa = Point(detection_x, detection_y)\n",
        "      pb = Point(label_x, label_y)\n",
        "      cls_overlap_area[detection_cls + 1] = distance(pa, pb)\n",
        "\n",
        "  writer.writerow(cls_overlap_area)\n",
        "csvfile.close()\n",
        "print('done')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
